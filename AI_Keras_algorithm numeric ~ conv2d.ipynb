{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aritificial intelligence assignment 2024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dit document wordt een model getraind op de mnist nummers dataset. Het model bevat 3 lagen (Flatten, Dense, Dense/output) \n",
    "waar nog mee geexperimenteerd is. Daarnaast wordt de standaard accuracy getoond voor het meten van de nauwkeurigheid van het model.\n",
    "De loss function sparse_categorical_crossentropy wordt gebruikt en de nauwkeurigheid van het model is het hoogst met epochs = 5 en \n",
    "validation_split=0.1. Dit betekend dat de dataset 5x door het model heen gehaald is met forward- en backward propogation.\n",
    "De validation_split van 0.1 betekend dat 1/100e van de trainingsset als validatie data/held out data dient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, SeparableConv2D, BatchNormalization\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize the pixel values to be between 0 and 1\n",
    "# x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "# x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "x_train = (x_train - 0.0) / (255.0 - 0.0)\n",
    "x_test = (x_test - 0.0) / (255.0 - 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "# Reshape the data if using convolutional neural networks (CNNs)\n",
    "# x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "# x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "x_train = x_train.reshape((x_train.shape + (1,)))\n",
    "x_test = x_test.reshape((x_test.shape + (1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (60000, 28, 28, 1)\n",
      "Test data shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Toon de data\n",
    "print(\"Training data shape:\", x_train.shape)\n",
    "print(\"Test data shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Maak de 28x28 array plat tot een 1 dimentionale array/ of \n",
    "# model.add(Flatten(input_shape=(28, 28)))\n",
    "\n",
    "#Check wat efficienter is voor de nauwkeurigheid van het model, Conv2D or double Dense layers\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the current model\n",
    "optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer=optimizer,\n",
    "                          loss='sparse_categorical_crossentropy',\n",
    "                          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na zorgvuldig testen is de conclusie dat er tussen de SDG optimizer en de adam optimizer weinig verschil zit in totale performance.\n",
    "De sdg optimizer gaat bij de eerste epoch trager, maar bij de tweede epoch sneller dan de adam optimizer wat in totaal uitkomt op hetzelfde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 71s 38ms/step - loss: 0.1863 - accuracy: 0.9420\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 69s 37ms/step - loss: 0.0524 - accuracy: 0.9839\n"
     ]
    }
   ],
   "source": [
    "# Train het model met validatie\n",
    "history = model.fit(x_train, y_train, epochs=2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 13, 13, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               204928    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 243,786\n",
      "Trainable params: 243,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 2.3082 - accuracy: 0.0939\n",
      "Test nauwkeurigheid: 0.0939\n"
     ]
    }
   ],
   "source": [
    "# Evalueer het model op de testset\n",
    "test_loss, test_accuracy = model_for_pruning.evaluate(x_test, y_test)\n",
    "\n",
    "print(f\"Test nauwkeurigheid: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelgrootte: 0.93 MB\n"
     ]
    }
   ],
   "source": [
    "# Modelgrootte berekenen\n",
    "model_size = model.count_params()\n",
    "model_memory = model_size * 4 / (1024 ** 2)  # 4 bytes per 32-bit float\n",
    "print(f\"Modelgrootte: {model_memory:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In dit deel wordt een nauwkeurigheid van het model getoond door middel van de confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Maak voorspellingen op de testset\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verwarringsmatrix:\n",
      "[[ 970    0    1    0    0    0    1    3    5    0]\n",
      " [   0 1110    2    4    0    0    5    3   11    0]\n",
      " [   1    0 1026    0    0    0    0    3    2    0]\n",
      " [   0    0    3 1003    0    0    0    2    2    0]\n",
      " [   0    0    3    1  953    0    4    0    4   17]\n",
      " [   1    0    0   24    0  857    1    1    2    6]\n",
      " [   5    2    0    0    1    4  945    0    1    0]\n",
      " [   0    0    7    6    0    0    0 1010    1    4]\n",
      " [   2    0    3    1    0    1    0    3  963    1]\n",
      " [   2    2    0    5    1    0    0    5    3  991]]\n"
     ]
    }
   ],
   "source": [
    "# Bereken de verwarringsmatrix\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "print(\"Verwarringsmatrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De verwarringsmatrix is te lezen als volgt:\n",
    "De x as moeten de getallen van 0 tm 9 bevatten die het model voorspelt.\n",
    "De y as moeten de getallen zijn die gelabeld zijn als 0 tm 9.\n",
    "\n",
    "In deze matrix kunnen we zien dat klasse 8 op de y-as het meest fout gedaan wordt door het model. Daarnaast kan hieruit geconcludeerd worden dat klasse 7 op de x as het meest fout geraden is door het model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
